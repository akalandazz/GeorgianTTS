# Quick Start Guide - Georgian TTS Training

## ğŸš€ Setup (5 minutes)

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

**âš ï¸ SECURITY IMPORTANT:** Ensure PyTorch 2.6+ is installed (required for security fix):
```bash
pip install torch>=2.6.0 torchvision torchaudio
```

### 2. Prepare Your Data Structure
```
data/
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ sample_001.wav
â”‚   â”œâ”€â”€ sample_002.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ metadata.csv
```

### 3. Create metadata.csv
Format: `filename|text` (pipe-separated)

```csv
filename|text
sample_001.wav|áƒ”áƒ¡ áƒáƒ áƒ˜áƒ¡ áƒáƒ˜áƒ áƒ•áƒ”áƒšáƒ˜ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜
sample_002.wav|áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒ áƒ©áƒ”áƒ›áƒ˜ áƒ¡áƒáƒ›áƒ¨áƒáƒ‘áƒšáƒáƒ
sample_003.wav|áƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ áƒ áƒ áƒ’áƒáƒ™áƒ”áƒ—áƒáƒœ
```

**Important:** 
- Audio files must be WAV format
- One line per audio file
- Text must be in Georgian
- No header row needed

## ğŸ“ Step-by-Step Training

### Step 1: Prepare Data
```bash
python prepare_data.py
```

This will:
- âœ… Validate all audio files
- âœ… Resample to 16kHz
- âœ… Clean and normalize text
- âœ… Split into train/validation sets
- âœ… Create processed_data/ folder

### Step 2: Train Model
```bash
python trainer.py
```

Training will:
- Load SpeechT5 model
- Fine-tune on your Georgian data
- Save checkpoints every 500 steps
- Save final model to output/

**Expected time:** 2-12 hours depending on data size

### Step 3: Test Your Model
```bash
# Single text
python inference.py --text "áƒ”áƒ¡ áƒáƒ áƒ˜áƒ¡ áƒ¢áƒ”áƒ¡áƒ¢áƒ˜"

# Interactive mode
python inference.py --interactive

# Batch processing
python inference.py --batch texts.txt
```

## âš™ï¸ Configuration

Edit `config.py` to adjust:

### Common adjustments:
```python
BATCH_SIZE = 4          # Reduce if out of memory
LEARNING_RATE = 1e-5    # Increase if training too slow
NUM_EPOCHS = 50         # More epochs = better quality
SAMPLE_RATE = 16000     # Audio sample rate
```

### GPU Memory Issues?
```python
BATCH_SIZE = 2  # or 1
GRADIENT_ACCUMULATION_STEPS = 8  # Increase this
FP16 = True  # Enable mixed precision
```

## ğŸ“Š Monitoring Training

### TensorBoard (Real-time monitoring)
```bash
tensorboard --logdir logs/
```
Open browser: http://localhost:6006

### Look for:
- âœ… Loss decreasing over time
- âœ… Validation loss following training loss
- âš ï¸ If validation loss increases: reduce learning rate or stop training

## ğŸ¯ Data Quality Tips

### Good Audio:
âœ… Clear speech, minimal background noise
âœ… Consistent volume levels
âœ… Native Georgian speaker
âœ… Natural speaking pace
âœ… 1-20 seconds per clip

### Good Text:
âœ… Matches audio exactly
âœ… Proper Georgian spelling
âœ… Natural sentences
âœ… No special symbols or numbers (write them out)

### How Much Data?
- **Minimum:** 30 minutes (200-300 samples)
- **Good:** 2 hours (800-1000 samples)  
- **Excellent:** 5+ hours (2000+ samples)

## ğŸ› Troubleshooting

### "CUDA out of memory"
```python
# In config.py
BATCH_SIZE = 1
GRADIENT_ACCUMULATION_STEPS = 16
```

### "Audio file not found"
- Check that audio files are in `data/audio/`
- Verify filenames in metadata.csv match exactly
- Ensure WAV format

### "Poor quality output"
- Train for more epochs
- Check training data quality
- Ensure transcriptions are accurate
- Try lower learning rate: `LEARNING_RATE = 5e-6`

### "Training very slow"
- Increase batch size if GPU memory allows
- Reduce audio quality: `SAMPLE_RATE = 16000`
- Use fewer workers: `DATALOADER_NUM_WORKERS = 2`

## ğŸ“ File Outputs

After training, you'll have:
```
â”œâ”€â”€ processed_data/     # Preprocessed dataset
â”œâ”€â”€ checkpoints/        # Training checkpoints
â”œâ”€â”€ output/            # Final trained model â­
â”œâ”€â”€ logs/              # Training logs
â””â”€â”€ output_001.wav     # Generated speech samples
```

## ğŸ¤ Using Your Trained Model

### Python API
```python
from inference import generate_speech

generate_speech(
    text="áƒ”áƒ¡ áƒáƒ áƒ˜áƒ¡ áƒ¢áƒ”áƒ¡áƒ¢áƒ˜",
    model_path="output/",
    output_path="my_speech.wav"
)
```

### Command Line
```bash
python inference.py --text "áƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ" --output hello.wav
```

## ğŸ”„ Next Steps

1. **Test quality:** Generate speech with various texts
2. **Iterate:** If quality is poor, gather more data and retrain
3. **Fine-tune:** Adjust hyperparameters in config.py
4. **Deploy:** Integrate into your application
5. **Share:** (Optional) Upload to Hugging Face Hub

## ğŸ’¡ Tips for Best Results

1. **Use consistent recording setup** for all audio
2. **Include variety** in text (questions, statements, emotions)
3. **Start small** (100 samples) to verify pipeline works
4. **Monitor training** using TensorBoard
5. **Save checkpoints** - earlier checkpoints might sound better
6. **Test regularly** during training

## ğŸ“š Need Help?

- Check the full guide: `TTS_FINETUNING_GUIDE.md`
- Review config options: `config.py`
- Inspect your data: `python prepare_data.py`

## âœ¨ Example Workflow

```bash
# 1. Setup
pip install -r requirements.txt

# 2. Prepare data
python prepare_data.py

# 3. Train (takes several hours)
python trainer.py

# 4. Test
python inference.py --interactive

# 5. Monitor
tensorboard --logdir logs/
```

Good luck with your Georgian TTS model! ğŸ‰
